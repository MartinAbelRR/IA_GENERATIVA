{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 1. Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint # Utilizar LLM open source que esta alojado en HuggingFace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Instanciar un Objeto de Modelo de Lenguaje de HuggingFaceEndpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí estamos creando una instancia de un objeto de modelo de lenguaje llamado `HuggingFaceEndpoint`, para nuestra tarea de procesamiento de lenguaje natural.\n",
    "\n",
    "Se proporciona el parámetro `repo_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFaceEndpoint(repo_id= \"mistralai/Mistral-7B-Instruct-v0.3\") # Instanciar el modelo LLM de HuggingFace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí el modelo de lenguaje es representado por el objeto `llm`. Que se utiliza para generar una respuesta basada en una consulta específica. \n",
    "\n",
    "La consulta, almacenada en la variable `our_query`, se pasa al modelo a través del objeto `llm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El LLM toma un prompt como una entrada y genera una salida basada en el prompt.\n",
    "our_query = \"Cúal es la mooneda del Perú?\" # Definir el prompt.\n",
    "\n",
    "response = llm.invoke(our_query) # Generar una respuesta basada en el prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "La moneda del Perú es el Sol. El Sol se introdujo en 1991 para reemplazar al Inti, que había estado en circulación desde 1985. El Sol es una moneda de plástico de diferentes colores, que representa la bandera nacional del Perú. Las monedas están disponibles en denominaciones de 5, 10, 20 y 50 centavos, y 1, 2 y 5 soles.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Instanciar un Objeto de Modelo de Lenguaje de OpenAI (De Paga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí estamos creando una instancia de un objeto de modelo de lenguaje llamado `OpenAI`, para nuestra tarea de procesamiento de lenguaje natural.\n",
    "\n",
    "Se proporciona el parámetro `azure_endpoint` y `api_version`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint= \"https://open-ai-ma.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-08-01-preview\",\n",
    "    api_version= '2024-08-01-preview'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí el modelo de lenguaje es representado por el objeto `llm`. Que se utiliza para generar una respuesta basada en una consulta específica. \n",
    "\n",
    "La consulta, almacenada en la variable `our_query`, se pasa al modelo a través del objeto `llm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_query = \"¿Cuál es la moneda de Perú?\" # Definir el prompt.\n",
    "\n",
    "response = llm.invoke(our_query) # Generar una respuesta basada en el prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'La moneda de Perú es el sol. Su símbolo es \"S/\" y su código ISO es PEN.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
